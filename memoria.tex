%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemas y Comunicaciones
%%     Escuela Técnica Superior de Ingenieros de Telecomunicación
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La última versión de esta plantilla está siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las imágenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper, 12pt]{book}
%\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
%\usepackage[spanish]{babel} % Comenta esta línea si tu memoria es en inglés
\usepackage[spanish,es-tabla]{babel}
\usepackage{url}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de índice
\usepackage{latexsym}  %% Logo LaTeX

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\title{Marco de trabajo para evaluar la relevancia de los artículos en el dominio científico}
\author{Adrián Alonso Barriuso}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

\renewcommand{\refname}{Bibliografía}  %% Renombrando
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} &
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
MÁSTER EN INGENIERÍA EN SISTEMAS DE DECISIÓN

\vspace{0.4cm}

\large
Curso Académico 2018/2019

\vspace{0.8cm}

Trabajo Fin de Máster

\vspace{2.5cm}

\LARGE
Marco de trabajo para evaluar la relevancia de los artículos en el dominio científico

\vspace{4cm}

\large
Autor : Adrián Alonso Barriuso \\
Tutor : Dr. Alberto Fernández Isabel

\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\pagenumbering{arabic}

\begin{flushright}
\textit{Dedicado a \\
mi familia, pareja, amigos y a todos los que me aguantan, en el buen sentido.}
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos

\chapter*{Agradecimientos}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen

\chapter*{Resumen}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
La comunidad investigadora se enfrenta cada vez a un mayor número de publicaciones y tendenencias que deben atender a la hora hacer sus propias publicaciones. Estos tópicos y tendencias  son estado del arte en el momento de su publicacón o presentación en conferencias, no obsante, pueden perder relevancia con el paso del tiempo. Esta medida de relevancia de publicaciones representa un desafío para la comunidad investigadora, la cuál invierte mucho tiempo leyendo literatura a menudo desafasada o poco relevante. Para abordar este problema, se introduce un marco de trabajo para evaluar la relevancia de artículos científicos a través de, principipalmente, un lexicón y una red neuronal. Se han llevado a cabo diversos expermientos aplicados al dominio de la medicina que demuestran el buen funcionamiento del marco de trabajo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en inglés

\chapter*{Summary}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el índice
\markboth{SUMMARY}{SUMMARY} % encabezado


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Las buenas noticias es que los índices se generan automáticamente.
% Lo único que tienes que hacer es elegir cuáles quieren que se generen,
% y comentar/descomentar esa instrucción de LaTeX.

%%%% Índice de contenidos
\tableofcontents 
%%%% Índice de figuras
\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%%%% Índice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducción}
\label{sec:intro} % etiqueta para poder referenciar luego en el texto con ~
En este capítulo introductorio se presenta, en primer lugar, el contexto científico sobre el que se enmarca el presente proyecto. Después, se introduce el objetivo principal y finalmente los objetivos específicos.

\section{Contexto}
\label{sec:contexto}

La comunidad investigadora invierte la mayor parte de su tiempo  documentándose, investigando literatura previa y el estado del arte. A menudo, la relevancia de los diferentes tópicos sobre los que se investiga fluctúa en gran medida con el tiempo, lo que provoca que a menudo los investigadores pierdan mucho tiempo con literatura desfasada o poco relevante. Por tanto, este trabajo introduce un marco de trabajo completo que tiene como finalidad organizar y medir la relevancia de artículos de investigación.

Dado que se trabaja con información textual, se utilizan técnicas de Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) \cite{jurafsky2014speech} que sirven para poder tratar con este tipo de información desde un punto de vista computacional. A través de estas técnicas, las cuáles se combinan con métricas de reputación \cite{josang2007survey}, se construye un lexicón de relevancias para evaluar la relevancia de los documentos de un modo similar a un análisis de sentimientos \cite{de2018visual}. Para complementar este lexicón, se emplean técnicas de Deep Learning \cite{lecun2015deep} para evaluar la relevancia de los términos cuya relevancia sea desconocida por el lexicón.

\subsection{Dominio de aplicación}
\label{sec:dominio}

Aunque este marco de trabajo puede ser entrenado para cualquier dominio de investigación científica, los experimentos se han llevado a cabo en el dominio médico. Se han descargado y parseado mas de dos millones de artículos de investigación médica provenienyes de Pubmed Central . Cabe destacar que, aunque los artículos de investigacion podrían ser considerados un dominio de aplicación por si mismo, la ciencia abarca demasiados temas para que el sistema funciona de forma deseable, por tanto, el sistema sólo debe ser utilizado apra evaluar los documentos del mismo dominio de aplicación concreto con el que haya sido entrenado.



\section{Objetivos}
\label{sec:objetivos}

El principal objetivo del presente trabajo es la creación del sistema completo de evaluación de relevancias, lo que comprende un marco de trabajo que incluye la interfaz para la introducción de documentos y a la salida devuelva la relevancia de los mismos.

\subsection{Objetivos específicos}
\label{sec:obepescificos}

\begin{itemize}
\item Obtención del corpus de documentos científicos: Se necesita un gran volumen de documentos para la creación del lexicón, el entrenamiento de la red neuronal y para la validación del sistema. 
\item Limpieza y almacenaje de los documentos: Una vez descargados, deben ser limpiados y debidamente almacenados en base de datos. Se almacenan con los metadatos necesarios para la creación del lexicón y la red neuronal, como la fecha, el DOI, el resumen y la reputación de cada artículo.
\item Construcción del lexicón de relevancias: Se aplican diversas métricas para la creación del lexicón. A mayor volumen de documentos utilizado, mayor riqueza y precisión del lexicón, lo que implica una menor dependencia de la red neuronal.
\item Construcción de la red neuronal: Debido a las limitaciones del lexicón, ya sea por limitaciones computacionales o de volumen de corpus considerado, se crea una red neuronal de apoyo para predecir las relevancias fuera del lexicón.
\item Creación del flujo de evaluación de relevancia: Se analizan documentos o textos nuevos combinando las métricas de relevancia proporcionadas por el lexicón, la red neuronal y la reputación para estimar la relevancia de los mismos.
\end{itemize}

\section{Estructura de la memoria}
\label{sec:estructura}

La memoria tiene los siguientes capítulos fundamentales:

\begin{enumerate}
\item Introducción.
\item Estado del arte: En este capítulo se revisa la literatura en la que se apoya el siguiente trabajo, explicando ideas utilizadas y otras descartadas
\item Propuesta: Se trata del capítulo central y más importante, en el cuál se describe la propuesta del marco de trabajo completo.
\item Experimentos y resultados: Se describe el caso uso del marco de trabajo, presentando los diferentes experimentos realizados.
\item Conclusiones: En este capítulo final se evalúan los resultados obtenidos y objetivos completados. También se revisan posibles líneas futuras de investigación y mejora.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ESTADO DEL ARTE %el
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Estado del arte}


\section{Algoritmos de reputación}
\label{sec:alrepus}


\section{Obtención de relevancias}
\label{sec:oreles}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DISEÑO E IMPLEMENTACIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Propuesta}
\label{chap:propuesta}
En este capítulo, se describe la propuesta del sistema completo, definiendo entradas y salidas explicadas a nivel de diseño. Se empieza con una subsección donde se ve la arquitectura y el propósito general y después se entra en detalle para cada uno de los módulos en las subsiguientes secciones.

\section{Arquitectura general} 
\label{sec:arquitectura}
En la Figura \ref{fig:arquitectura}, se pueden observar el módulo principal: \textit{Relevance estimator module}, que es el encargado de estimar las relevancias de los artículos de entrada, y sus correspondientes submódulos: \textit{Text processor, Reputation calculator y Relevance calculator}. Se cuenta además, con dos fuentes de información precalculadas utilizadas por el submódulo \textit{Relevance calculator}, a saber, \textit{Relevance lexicon} que consiste en cuatro lexicones\cite{pustejovsky1991generative} de relevancias de términos médicos y \textit{Neural network}, que consiste en cuatro modelos entrenados de redes neuronales convolucionales (CNN)\cite{poria2015deep} por sus siglas en inglés. Por otra parte, se cuenta con un módulo de visualización(\textit{Visualization}), que se utiliza para ver la salida del sistema y para proporcionar la entrada (\textit{Text}). Por último, se utiliza una fuente de información externa en tiempo real (\textit{Web information resources}).

En primer lugar se entra en detalle en cómo se construye Relevance lexicon, después Neural network y, por último, Relevance estimator module, el cuál emplea todo lo anterior para calcular las relevancias de nuevos documentos.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/architecture}
  \caption{Arquitectura general}
  \label{fig:arquitectura}
\end{figure}

\section{Creación del lexicón de relevancias} 
\label{sec:lex}
El lexicón de relevancias tiene un papel fundamental a la hora de estimar la relevancia de los artículos, en concreto, contiene la relevancia de las palabras de el dominio de aplicación utilizado para crear el mismo. Para la creación del lexicón se ha diseñado un marco de trabajo completo, cuya arquitectura puede verse en la Figura \ref{fig:train_lexicon}. Esta cuenta con un módulo de extracción, transformación y carga (ETL por sus siglas en inglés)\cite{vassiliadis2009survey}, un módulo de gestión de conomicimiento (Knowledge managment) y uno de visualización. Se cuenta, además, con dos bases de datos, una orientada a documentos\cite{han2011survey}(Document knowledge consolidation) y una ElasticSearch\cite{gormley2015elasticsearch} para visualización con Kibana \cite{gupta2015kibana}.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/train_lexicon}
  \caption{Arquitectura de generación de lexicones}
  \label{fig:arquitectura}
\end{figure}

\subsection{Módulo ETL} 
\label{sec:etl}

El módulo ETL se encarga de la obtención y el preprocesado del corpus de artículos médicos. Se divide a su vez en dos submódulos: Corpus processor y Reputation calculator.
Corpus processor obtiene artículos de Pubmed Central\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc/}} utilizando técnicas de web scrapping \cite{mitchell2018web}. Estos artículos en formato XML \cite{bray2000extensible}, son parseados y almacenados en formato JSON \cite{crockford2006application} en Document knowledge consolidation con una estructura de párrafos y frases, eliminando tablas, gráficas u otros artefactos no aprovechables por el sistema.
Una vez un documento se almacena en la base de datos, se procede a calcular su resumen automático aplicando el clásico algoritmo Text Rank \cite{mihalcea2004textrank} utilizando una popular implementación en Python \cite{DBLP:journals/corr/BarriosLAW16}. Este tipo de resúmenes ofrecen una ordenación de las frases de un documento por relevancia, sirviendo como factor de filtrado de información poco relevante o redundante y a la vez como factor de compresión, haciendo la información más manejable en memoria. Se obtiene un 20 porciento del tamaño original de los artículos y se almacena como un nuevo artibuto del documento en la base de datos.

Una vez preprocesados y almacenados los artículos, emph{Reputation calculator} calcula la reputación de los mismos para que esta sea añadida como nuevo atributo y ser utilizada posteriormente por el módulo Knowledge managment.
El algoritmo de reputación empleado es una adaptación del introducido en el artículo \cite{fernandez2018unified}. La reputación a priori de un artículo viene dada por:
\begin{equation}
\label{eq:1}
	rep_{p} = \alpha \cdot rep\_authors_{p} + (1 - \alpha) \cdot citations_{p} \,,
\end{equation}

donde  $rep\_authors_{p}$ es la reputación media del los autores del artículo y $citations_{p}$ su número de citas total en el momento de la consulta. El parámetro $\alpha \in (0,1)$ actúa como modulador de importancia relativa entre las citas y los autores. La reputación de cada autor viene dada por:
\begin{equation}
\label{eq:3}
	rep_{i} = \omega_1 \cdot inf\_citation\_count + \omega_2 \cdot citation\_velocity + \omega_3 \cdot seniority + \omega_4 \cdot papers \,,
\end{equation}

donde $\sum_{i=1}^4\omega_i=1$. El parámetro $inf\_citation\_count$ representa el número de citas altamente influyentes del autor. \cite{valenzuela2015identifying}. $citation\_velocity$ indica lo popular que es el autor durante los últimos 3 años. $seniority$ es la cantidad de años transcurridos entre la primera y última publicación del autor. Por último, $papers$ es el número total de artículos publicados por el autor. 
Estos parámetros son extraídos de  la API REST de Semantic Scholar\cite{semanticscholar2018sc} a través del Identificador Digital de Objeto (DOI, por sus siglas en inglés)\cite{paskin2010digital} del documento. Una vez que el módulo Reputation Calculator ha calculado la reputación del artículo, esta se añade a \emph{Document knowledge consolidation}, como un atributo nuevo.

\subsection{Módulo de Gestión del conocimiento} 
\label{sec:know}
Este módulo consulta \emph{Document knowledge consolidation} y sirviéndose de 3 submódulos, construye finalmente el lexicón. Estos 3 submódulos son Text filter, Text normalizer y Lexicon builder.

\subsection{Text filter} 
\label{sec:filter}

Este módulo analiza los resúmenes extraidos por el módulo ETL por cada documento, aplicando técnicas de procesamiento de lenguaje natural (NLP) \cite{jurafsky2014speech} extrayendo los sustantivos y eliminando palabras vacías \cite{chandramouli2018domain}, tanto genéricas como de dominio médico\cite{gupta2015distantly} y académico\cite{seinecleStopwords2016}. Finalmente, se obtienen los lemas de los sustantivos, lo que permite cierta desambiguación, ya que el lema de una palabra depende de la función sintáctica de la misma. Además, se resuelven posibles conflictos entre mayúsculas, minúsculas, singulares y plurales.

\subsection{Text normalizer} 
\label{sec:filter}
Este submódulo construye una matriz de términos por documentos \cite{anandarajan2019term} a partir de la cuál construye la matriz TF-IDF \cite{ramos2003using}. Los pesos resultantes se combinan con las reputaciones de los artículos dando la medida de relevancia de cada término $rel\_lex_{t}$. La relevancia de cada término $t$ en los  $N$ artículos pertenecientes al corpus $C$ viene dada por:

\begin{equation}
	rel\_lex_{t} =\log\left(\frac{1}{N} \cdot \sum \limits_{p=1}^N \beta  \cdot tfidf(t)_p + (1-\beta) \cdot rep_p\right), \forall p \in C \,,
\end{equation}

donde $rep_p$ es la reputación del artículo $p$, $tfidf(t)_p$ es el valor TF-IDF del término $t$ en el artículo $p$ y $\beta \in (0,1)$ es otro parámetro que modula la importancia relativa del valor TF-IDF sobre la reputación. Cabe destacar que $tfidf(t)_p \in (0,1)$ ya que han sido normalizados por simplicidad y se aplica el logaritmo para normalizar la distribución.

\subsection{Lexicon builder} 
\label{sec:filter}
Este componente construye y organiza el lexicón a partir del texto normalizado. Contempla además la posibilidad de ponderar aún más el peso de aquellos términos de dominio específico proporcionados por un diccionario, médico en este caso \cite{webster2017merriam}. 

Se organizan y construyen lexicones por cada conjunto de artículos correspondientes a cada año disponible, teniendo en cuenta la evolución de la relevancia de cada término a lo largo de los años. De esta manera se puede modular la curva de olvido \cite{averell2011form} y tener en consideración las tendencias del dominio de aplicación.


Se construyen diferentes valores de relevancia para cada término específico $rel\_lex_{t}(y)$ de acuerdo a un año específico $y$, manteniendo las palabras del año anterior en el nuevo de la forma:

\begin{equation}
	rel\_lex_{t}(y) = \rho \cdot rel\_lex_{t} + (1-\rho)\cdot rel\_lex_{t}(y-1) \,,
\end{equation}

donde $rel\_lex_{t}$ es la relevancia proporcionada por el marco de trabajo para el término $t$ y $rel\_lex_{t}(y-1)$ es la correspondiente al año anteruir $y-1$. El parámetro $\rho$ controla el peso del año anterior.

\section{Creación del la red neuronal} 
\label{sec:lex}

Por muy grande que sea el corpus que se utilice para la creación de los lexicones, es virtualmente imposible contar con la relevancia de todos los términos existentes. Por tanto, se ha desarrollado una Red Neuronal Convolucional (CNN, por sus siglas en inglés)\cite{poria2015deep} para servir de apoyo al sistema. El propósito de la red es predecir la relevancia de aquellas frases que no contengan ninguna palabra presente en el lexicón. En la Tabla \ref{tab:cnn} se puede ver la configuración de la misma, la cuál es una versión optimizada de la aproximación introducida en \cite{bhavsar2017natural}. Cabe destacar que la capa de \textit{embedding} utiliza un modelo pre-entrenado de Glove \cite{pennington2014glove} con un vocabulario de  $400,000$ palabras de  Wikipedia \cite{o2016wikipedia}. La capa de salida cuenta con activación \textit{softmax}, la cuál proporciona valores entre $0$ y $1$. En las capas ocultas se cuenta con convoluciones, funciones de activación  \textit{relu} y funciones de \textit{dropout}.

Para construir la red, se propone la siguiente metodología: En primer lugar, el usuario selecciona un conjunto de artículos del corpus que no hayan sido utilizados para construir el lexicón. Después, se  procesa el texto separando por frases y términos, eliminando palabras vacías y lematizando de manera análoga a como se procede en el módulo de ETL, de esta manera se aumenta el número potencial de coincidencias entre el texto utilizado para la creación de la red y las palabras del lexicón. Se etiquetarán como relevantes ($1$) aquellas frases con mayor relevancia de acuerdo al lexicón y como no relevantes ($0$) las menor relevancia o aquellas que no contengan palabras del lexicón. Se define, por tanto, 
un umbral de relevancia $\epsilon$ para elegir el mínimo necesario de acuerdo a lo estricta que se quiere que sea la red neuronal. Finalmente se debe elegir el número de frases etiquetadas para conformar el conjunto de entrenamiento y test. La red neuronal resultante debería ser capaz de prececir la relevancias de las frases sin palabras del lexicón.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{c}
			\hline
			\textbf{Layers} \\
            \hline
			\multicolumn{1}{l}{1. Embedding input\_dim 400000 output\_dim 50} \\
			\multicolumn{1}{l}{2. Dropout rate 0.4} \\
			\multicolumn{1}{l}{3. Conv1D 250 filters of 3 with stride 1} \\
            \multicolumn{1}{l}{4. Pool1D (max) with stride 1} \\
            \multicolumn{1}{l}{5. Dense units 250} \\
            \multicolumn{1}{l}{6. Dropout rate 0.4} \\
            \multicolumn{1}{l}{7. Relu} \\
            \multicolumn{1}{l}{8. Dense units 1} \\
            \multicolumn{1}{l}{9. Softmax} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Capas de la red neuronal convolucional.}
	\label{tab:cnn}
\end{table}

\section{Estimación de relevancias de artículos} 
\label{sec:full_process}

Se ha diseñao un flujo de trabajo para ilustrar como funciona todo el proceso del marco de trabajo. Se comienza eligiendo un texto para evaluar y se concluye devolviendo su relevancia normalizada entre $0$ y $1$ (ver Figura. \ref{fig:pipeline}).

\begin{figure}
  \centering
  \includegraphics[width=8cm, keepaspectratio]{img/pipeline_2}
  \caption{Flujo de trabajo de cálculo de relevancia de un artículo}
  \label{fig:arquitectura}
\end{figure}

En primer el sistema detecta si el documento  cuya relevancia se desea conocer consiste en texto plano o un fichero (de tipo PDF, html o similar). En caso de ser un fichero, este parseado, limpiado y partido en frases y párrafos. Estas tareas se llevan a cabo en los pasos \emph{Parse to raw text} y \emph{Clean and tokenize sentences}, respectivamente.

Una vez se tienen mapeados los párrafos en listas de lemas de sustantivos, se consulta el lexicón por cada lista, acumulando el valor de relevancia de cada lema. En caso de que una frase no contenga ningún lema presente en el lexicón, la lista de lemas se tranforma en los vectores que entran a la red neuronal, que devuelve la predicción de relevancia. Estas tareas son llevadas a cabo por el módulo \emph{Relevance calculator}. Una vez recorridas todas las listas de lemas, la relevancia viene dada por la Ecuación:
\begin{equation}
	combined\_rel_{p} = \theta \cdot rel\_lex_{p} + (1-\theta) \cdot \frac{1}{K} \sum \limits_{k=1}^K rel\_neural(s_k)\,,
    \label{eq:7}
\end{equation}

donde $rel\_lex_p$ es la relevancia media del artcículo proporcionada por el lexicón, $\{s_k\}_{k=1}^K$ es el conjunto de frases cuya relevancia es desconocida y $rel\_neural$ es la relevancia predicha por la red neuronal para cada $s_k$. El parámetro $\theta \in (0,1)$ parameter modula la importancia relativa de la red neuronal.

En última instancia, en caso de que la entrada al sistema sea un documento y no texto plano, se comprueban los metadados del mismo para tratar de encontrar el DOI. En caso de estar disponible, el módulo \emph{Relevance calculator}, calcula su reputaciñón y esta es utilizada para calcular la relevancia final del documento, la cuál viene dada por:

\begin{equation}
	combined\_rel\_doi_{p} = \gamma \cdot combined\_rel_{p} + (1-\gamma)\cdot rep_{p} \,,
    \label{eq:8}
\end{equation}

donde $combined\_rel_p$ es la relevancia combinada del lexicón y la red neuronal para el artcículo y $rep_p$ es su reputación. El parámetro $\gamma \in (0,1)$ modula, su importancia relativa.

En caso de que el DOI no esté disponible, se devuelve el resultado de la Ecuación \ref{eq:7} como medida de relevancia final.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESULTADOS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Experimentos y resultados}
\label{chap:resus}



\section{Planificación temporal}
\label{sec:planificacion-temporal}
En la Figura \ref{fig:gantt} se puede ver un diagrama de Gantt\cite{wilson2003gantt} que refleja el tiempo empleado en cada una de las fases del proyecto.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/gantt.png}
  \caption{Diagrama de Gantt del desarrollo}
  \label{fig:gantt}
\end{figure}   

\section{Experimentos}
\label{sec:experimentos}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones}
\label{chap:conclusiones}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

% Las siguientes dos instrucciones es todo lo que necesitas
% para incluir las citas en la memoria
\bibliographystyle{unsrt}
\bibliography{memoria}  % memoria.bib es el nombre del fichero que contiene
% las referencias bibliográficas. Abre ese fichero y mira el formato que tiene,
% que se conoce como BibTeX. Hay muchos sitios que exportan referencias en
% formato BibTeX. Prueba a buscar en http://scholar.google.com por referencias
% y verás que lo puedes hacer de manera sencilla.
% Más información: 
% http://texblog.org/2014/04/22/using-google-scholar-to-download-bibtex-citations/

\end{document}
