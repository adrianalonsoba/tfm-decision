%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemas y Comunicaciones
%%     Escuela Técnica Superior de Ingenieros de Telecomunicación
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La última versión de esta plantilla está siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las imágenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{empty}
\documentclass[a4paper, 12pt]{book}
%\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
%\usepackage[spanish]{babel} % Comenta esta línea si tu memoria es en inglés
\usepackage[spanish,es-tabla]{babel}
\usepackage{url}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de índice
\usepackage{latexsym}  %% Logo LaTeX

\usepackage{graphicx} % figuras
\usepackage{subfigure} % subfiguras

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\title{Marco de trabajo para evaluar la relevancia de artículos de dominio científico}
\author{Adrián Alonso Barriuso}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

\renewcommand{\refname}{Bibliografía}  %% Renombrando
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} &
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
MÁSTER EN INGENIERÍA EN SISTEMAS DE DECISIÓN

\vspace{0.4cm}

\large
Curso Académico 2018/2019

\vspace{0.8cm}

Trabajo Fin de Máster

\vspace{2.5cm}

\LARGE
Marco de trabajo para evaluar la relevancia de artículos de dominio científico

\vspace{4cm}

\large
Autor : Adrián Alonso Barriuso \\
Tutor : Dr. Alberto Fernández Isabel

\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina

\clearpage
\thispagestyle{empty}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\thispagestyle{empty}
\begin{flushright}
\textit{Dedicado a \\
mi sobrino, Alberto, algún día te explicaré todo esto....}
\end{flushright}
\pagestyle{empty}
\thispagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos
\pagestyle{empty}
\thispagestyle{empty}

\chapter*{Agradecimientos}
\thispagestyle{empty}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado 
\thispagestyle{empty}

Gracias a mi familia y amigos por estar ahí cuando había que estar. Gracias a todos los compañeros del DSLAB por vuestra ayuda e inspiración, mención especial para Isaac. Gracias a Medlab Media Group y a mi tutor, Alberto, por vuestra confianza y apoyo.
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen
\thispagestyle{empty}

\chapter*{Resumen}
\thispagestyle{empty}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice

La comunidad investigadora se enfrenta cada vez a un mayor número de publicaciones y tendencias que deben atender a la hora hacer sus propias publicaciones. Estos tópicos y tendencias  son estado del arte en el momento de su publicación o presentación en conferencias, no obstante, pueden perder relevancia con el paso del tiempo. Esta medida de relevancia de publicaciones representa un desafío para la comunidad investigadora, la cuál invierte mucho tiempo leyendo literatura a menudo desfasada o poco relevante. Para abordar este problema, se introduce un marco de trabajo para evaluar la relevancia de artículos científicos a través de, principalmente, un lexicón y una red neuronal. Se han llevado a cabo diversos experimentos aplicados al dominio de la medicina que demuestran el buen funcionamiento del marco de trabajo.

Palabras clave: Medida de relevancia, Generación de diccionario, Reputación de artículos, Relevancia científica, Sistema basado en conocimiento.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en inglés
\thispagestyle{empty}

\chapter*{Abstract}
\thispagestyle{empty}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el índice
\markboth{SUMMARY}{SUMMARY} % encabezado
The research community is faced with an increasing number of publications and trends that need to be taken into account when making their own publications. These topics and trends are state of the art at the time of publication or presentation at conferences, however, they may lose relevance over time. This measure of publication relevance represents a challenge for the research community, which spends a lot of time reading often outdated or irrelevant literature. To address this problem, a framework is introduced to assess the relevance of scientific articles primarily through a lexicon and neural network. Several experiments applied to the field of medicine have been carried out that demonstrate the good performance of the framework.

Keywords: Relevance metric, Dictionary generation, Article reputation, Scientific relevance, Knowledge based system
\thispagestyle{empty}

\pagestyle{empty}
\thispagestyle{empty}
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{empty}
\thispagestyle{empty}
\thispagestyle{empty}

% Las buenas noticias es que los índices se generan automáticamente.
% Lo único que tienes que hacer es elegir cuáles quieren que se generen,
% y comentar/descomentar esa instrucción de LaTeX.
\thispagestyle{empty}
\pagestyle{empty}
\thispagestyle{empty}

%%%% Índice de contenidos
\pagestyle{empty}
\thispagestyle{empty}
\pagestyle{empty}
\tableofcontents 
%%%% Índice de figuras
\pagestyle{empty}
\thispagestyle{empty}
\pagestyle{empty}
\cleardoublepage
\pagestyle{empty}
\thispagestyle{empty}
\pagestyle{empty}
\thispagestyle{empty}
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
\thispagestyle{empty}
\thispagestyle{empty}

%%%% Índice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas
\pagestyle{empty}
\thispagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}
\thispagestyle{empty}

\cleardoublepage
\thispagestyle{empty}
\setcounter{page}{1}
\pagestyle{plain}
\chapter{Introducción}
\label{sec:intro} % etiqueta para poder referenciar luego en el texto con ~
En este capítulo introductorio se presenta, en primer lugar, el contexto científico sobre el que se enmarca el presente proyecto. Después, se introduce el objetivo principal y finalmente los objetivos específicos.

\section{Contexto}
\label{sec:contexto}

La comunidad investigadora invierte la mayor parte de su tiempo  documentándose, investigando literatura previa y el estado del arte. A menudo, la relevancia de los diferentes tópicos sobre los que se investiga fluctúa en gran medida con el tiempo, lo que provoca que, en ocasiones, los investigadores pierdan mucho tiempo con literatura desfasada o poco relevante. Por tanto, este proyecto introduce un marco de trabajo completo que tiene como finalidad organizar y medir la relevancia de artículos de investigación.

Dado que se trabaja con información textual, se utilizan técnicas de Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) \cite{jurafsky2014speech} que sirven para poder tratar con este tipo de información desde un punto de vista computacional. A través de estas técnicas, las cuáles se combinan con métricas de reputación \cite{josang2007survey}, se construye un lexicón de relevancias para evaluar la relevancia de los documentos de un modo similar a un análisis de sentimientos \cite{de2018visual}. Para complementar este lexicón, se emplean técnicas de Deep Learning \cite{lecun2015deep} para evaluar la relevancia de los términos cuya relevancia sea desconocida por el lexicón y la reputación de cada artículo en caso de estar disponible.

\subsection{Dominio de aplicación}
\label{sec:dominio}

Aunque este marco de trabajo puede ser entrenado para cualquier dominio de investigación científica, los experimentos se han llevado a cabo en el dominio médico. Se han descargado y parseado mas de dos millones de artículos de investigación médica provenientes de Pubmed Central . Cabe destacar que, aunque los artículos de investigacion podrían ser considerados un dominio de aplicación por si mismo, la ciencia abarca demasiados temas para que el sistema funcione de forma deseable, por tanto, el sistema sólo debe ser utilizado para evaluar los documentos del mismo dominio de aplicación concreto con el que haya sido entrenado.

\section{Objetivos}
\label{sec:objetivos}

El principal objetivo del presente trabajo es la creación del sistema completo de evaluación de relevancias, lo que comprende un marco de trabajo que incluye la interfaz para la introducción de documentos y a la salida devuelva la relevancia de los mismos.

\subsection{Objetivos específicos}
\label{sec:obepescificos}

\begin{itemize}
\item Obtención del corpus de documentos científicos: Se necesita un gran volumen de documentos para la creación del lexicón, el entrenamiento de la red neuronal y para la validación del sistema. 
\item Limpieza y almacenaje de los documentos: Una vez descargados, deben ser limpiados y debidamente almacenados en base de datos. Se almacenan con los metadatos necesarios para la creación del lexicón y la red neuronal, como la fecha, el DOI, el resumen y la reputación de cada artículo.
\item Construcción del lexicón de relevancias: Se aplican diversas métricas para la creación del lexicón. A mayor volumen de documentos utilizado, mayor riqueza y precisión del lexicón, lo que implica una menor dependencia de la red neuronal.
\item Construcción de la red neuronal: Debido a las limitaciones del lexicón, ya sea por limitaciones computacionales o de volumen de corpus considerado, se crea una red neuronal de apoyo para predecir las relevancias fuera del lexicón.
\item Creación del flujo de evaluación de relevancia: Se analizan documentos o textos nuevos combinando las métricas de relevancia proporcionadas por el lexicón, la red neuronal y la reputación para estimar la relevancia de los mismos.
\end{itemize}

\section{Estructura de la memoria}
\label{sec:estructura}

La memoria tiene los siguientes capítulos fundamentales:

\begin{enumerate}
\item Estado del arte: En este capítulo se revisa la literatura en la que se apoya el siguiente trabajo, explicando ideas utilizadas y otras descartadas.
\item Propuesta: Se trata del capítulo central y más importante, en el cuál se describe la propuesta del marco de trabajo completo.
\item Experimentos y resultados: Se describe el caso uso del marco de trabajo, presentando los diferentes experimentos realizados.
\item Conclusiones: En este capítulo final se evalúan los resultados obtenidos y objetivos completados. También se revisan posibles líneas futuras de investigación y mejora.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ESTADO DEL ARTE %el
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Estado del arte}
\label{sec:alrepus}

En este capítulo se hace un análisis de la literatura relacionada con las diferentes características del presente trabajo. Se describen ideas utilizadas, modificadas y/ó descartadas con sus correspondientes referencias.

\section{Relevancia de documentos}
\label{sec:genlex}
Se define relevancia como importancia o cualidad de destacable. A lo largo de los años, se han propuesto diferentes aproximaciones matemáticas que determinan la relevancia de un texto, concepto o término. Debido a su simplicidad, eficacia y bajo coste computacional, el algoritmo \emph{TF-IDF}(Term Frequency - Inverse Document Frequency) \cite{ramos2003using} ha sido el más utilizado por la comunidad científica. Parte de la asunción de que cuanto más sea repetido un término o concepto dentro de un documento, más relevante es (Term Frequency) dentro del mismo. No obstante, si ese término es muy común en un conjunto de textos, su relevancia baja (Inverse Documento Frequency).
 A pesar de sus virtudes, sólo tener en cuenta la parte frecuencial de los términos le resta potencial, de ahí que la comunidad científica haya propuesto numerosas modificaciones \cite{wang2019feature} con resultados desiguales para resolver sus limitaciones, como el STW (supervised term weighting) \cite{debole2004supervised}, TF-RF(Term Frequency Relevance Frequency) \cite{lan2008supervised} o el más reciente TF-IGM \cite{chen2016turning}. Todas estas aproximaciones son interesantes, pero dada su mayor complejidad y falta de continuidad de uso por la comunidad investigadora, se ha optado por la utilización del TF-IDF, quedando su comparación con el resto de aproximaciones para trabajos futuros.

\section{Generación automática de lexicones}
\label{sec:genlex}

La generación automática de lexicones de propósito específico es un desafío al que la comunidad científica lleva años enfrentándose. La mayoría de lexicones creados hasta la fecha están elaborados, en el mejor de los casos, con métodos semi supervisados \cite{bracewell2008semi}. La mayoría de las aproximaciones realizadas tienen como objetivo el análisis de sentimientos \cite{pang2008opinion}, siendo el mayor exponente SentiWordNet \cite{esuli2007sentiwordnet}, el cuál está creado con técnicas de aprendizaje supervisado. Hay alguna propuesta novedosa de ténicas automáticas, como la introducida por \cite{wu2019automatic}, que tiene en cuenta caractéristicas sintácticas y semánticas de las palabras para construir un diccionario de sentiemientos. Parte del presente trabajo requiere de un lexicón generado de manera automática, pero de relevancias, no de sentimientos, por tanto este tipo de aproximaciones u otras mas recientes como la de \cite{deng2019sentiment} no son aplicables. Por otra parte, otras aproximaciones de gran relevancia actual, como la última versión de SenticNet \cite{cambria2018senticnet} , emplean redes neuronales recurrentes (RNN) para la construcción de su particular representación del conocimiento para la creación de un diccionario de sentimientos.

\section{Algoritmos de reputación}
\label{sec:repusalg}

Los algoritmos de reputación tienen como objetivo cuantificar la confianza de una persona u objeto específico en base a información previa \cite{josang2007survey}. Revisando la literatura más reciente al respecto, \cite{fernandez2018unified} propone un marco de trabajo visual para dar soporte a la comunidad científica. Una de sus principales funcionalidades es la de proporner un algoritmo de reputación de artículos de investigación, en base a métricas como la veteranía de los autores y el número de citas. 

Otras aproximaciones, como la propuesta en en artículo \cite{peleja2014reputation}, la cuál obtiene la reputación de críticas de películas, en base a principios similares a los empleados en la anterior publicación, como el número de citas de las críticas y el contexto en el que se encuentran, no obstante, los metadatos empleados para el cálculo sólo tienen sentindo dentro de este dominio de aplicación y no están disponibles para el presente caso. 

\section{Redes neuronales aplicadas a texto}
\label{sec:neuraltext}

Las redes neuronales sólo admiten números como entrada, por tanto, para que puedan ser usadas con información textual, se debe encontrar una forma de codificar el texto en números y vectores. La forma más sencilla de hacerlo podría ser la de asignar un número único de forma arbitraria a cada una de las diferentes palabras del corpus. Esto puede parecer suficiente para que la red neuronal aprenda patrones y pueda hacer predicciones. No obstante, esta codificación no contiene ninguna información sobre cómo las palabras se relacionan entre sí de manera semántica, por tanto se utilizan aproximaciones como el \textit{word embedding} \cite{tang2014learning}. Lo cuál consiste en mapear las relaciones semánticas de palabras en vectores, de forma que por ejemplo, los sinónimos tendrán vectores parecidos. Esta representación geométrica de el lenguaje elimina ruido y facilita el trabajo de las redes neuronales. Se ha utilizado un word embeding pre-entrenado con un vocabulario de $400000$ palabras de $100$ dimensiones de dominio general provenientes de Glove \cite{pennington2014glove}, queda por tanto, el entrenamiento propio de word embeddings para trabajos futuros. 
Más allá de representación óptima de palabras como vectores, la información textual tiene un orden temporal o secuencial, por lo que la utilización de redes neuronales convolucionales (CNN) \cite{poria2015deep} es una buena solución para tareas de clasificación de texto por encima de las redes neuronales recurrentes, ya que ofrecen un rendimiento similar con un menor coste computacional \cite{chollet2018deep}. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DISEÑO E IMPLEMENTACIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Propuesta}
\label{chap:propuesta}
En este capítulo, se describe la propuesta del sistema completo, definiendo entradas y salidas explicadas a nivel de diseño. Se empieza con una subsección donde se ve la arquitectura y el propósito general y después se entra en detalle para cada uno de los módulos en las subsiguientes secciones.

\section{Arquitectura general} 
\label{sec:arquitectura}
En la Figura \ref{fig:arquitectura}, se pueden observar el módulo principal: \textit{Estimador de relevancia}, que es el encargado de estimar las relevancias de los artículos de entrada, y sus correspondientes submódulos: \textit{Procesador de texto, Calculador de reputación y Calculador de relevancia}. Se cuenta además, con dos fuentes de información precalculadas utilizadas por el submódulo \textit{Calculador de relevancia}, a saber, \textit{Lexicón de relevancia} que consiste en cuatro lexicones\cite{pustejovsky1991generative} de relevancias de términos médicos y \textit{Red neuronal}, que consiste en cuatro modelos entrenados de redes neuronales convolucionales (CNN)\cite{poria2015deep} por sus siglas en inglés. Por otra parte, se cuenta con un módulo de visualización(\textit{Visualización}), que se utiliza para ver la salida del sistema y para proporcionar la entrada (\textit{Texto}). Por último, se utiliza una fuente de información externa en tiempo real.

En primer lugar se entra en detalle en cómo se construye Lexicón de relevancia, después Red neuronal y, por último, el módulo de estimación de relevancia completo, el cuál emplea todo lo anterior para calcular las relevancias de nuevos documentos.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/arc_esp.png}
  \caption{Arquitectura general}
  \label{fig:arquitectura}
\end{figure}

\section{Creación del lexicón de relevancias} 
\label{sec:lex}
El lexicón de relevancias tiene un papel fundamental a la hora de estimar la relevancia de los artículos, en concreto, contiene la relevancia de las palabras del dominio de aplicación utilizado para crear el mismo. Para la creación del lexicón se ha diseñado un marco de trabajo completo a parte, cuya arquitectura puede verse en la Figura \ref{fig:train_lexicon}. Esta cuenta con un módulo de extracción, transformación y carga (ETL por sus siglas en inglés)\cite{vassiliadis2009survey}, un módulo de gestión de conomicimiento y uno de visualización. Se cuenta, además, con dos bases de datos, una orientada a documentos\cite{han2011survey}(Consolidación de información de documentos) y una ElasticSearch\cite{gormley2015elasticsearch} para visualización con Kibana \cite{gupta2015kibana}.

\begin{figure}
  \centering
  \includegraphics[width=15cm, keepaspectratio]{img/lex_esp}
  \caption{Arquitectura de generación de lexicones}
  \label{fig:train_lexicon}
\end{figure}

\subsection{Módulo ETL} 
\label{sec:etl}

El módulo ETL se encarga de la obtención y el preprocesado del corpus de artículos médicos. Se divide a su vez en dos submódulos: Procesador del corpus y calculador de reputación.
Corpus processor obtiene artículos de Pubmed Central\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc/}} utilizando técnicas de web scrapping \cite{mitchell2018web}. Estos artículos en formato XML \cite{bray2000extensible}, son parseados y almacenados en formato JSON \cite{crockford2006application} en Consolidación de información de documentos con una estructura de párrafos y frases, eliminando tablas, gráficas u otros artefactos no aprovechables por el sistema.
Una vez un documento se almacena en la base de datos, se procede a calcular su resumen automático aplicando el clásico algoritmo Text Rank \cite{mihalcea2004textrank} utilizando una popular implementación en Python \cite{DBLP:journals/corr/BarriosLAW16}. Este tipo de resúmenes ofrecen una ordenación de las frases de un documento por relevancia, sirviendo como factor de filtrado de información poco relevante o redundante y a la vez como factor de compresión, haciendo la información más manejable en memoria. Se obtiene un 20 porciento del tamaño original de los artículos y se almacena como un nuevo artibuto del documento en la base de datos.

Una vez preprocesados y almacenados los artículos, \emph{Calculador de reputación} calcula la reputación de los mismos para que esta sea añadida como nuevo atributo y ser utilizada posteriormente por el Módulo de gestión del conocimiento.
El algoritmo de reputación empleado es una adaptación del introducido en el artículo \cite{fernandez2018unified}. La reputación a priori de un artículo viene dada por:
\begin{equation}
\label{eq:1}
	rep_{p} = \alpha \cdot rep\_authors_{p} + (1 - \alpha) \cdot citations_{p} \,,
\end{equation}

donde  $rep\_authors_{p}$ es la reputación media del los autores del artículo y $citations_{p}$ su número de citas total en el momento de la consulta. El parámetro $\alpha \in (0,1)$ actúa como modulador de importancia relativa entre las citas y los autores. La reputación de cada autor viene dada por:
\begin{equation}
\label{eq:3}
	rep_{i} = \omega_1 \cdot inf\_citation\_count + \omega_2 \cdot citation\_velocity + \omega_3 \cdot seniority + \omega_4 \cdot papers \,,
\end{equation}

donde $\sum_{i=1}^4\omega_i=1$. El parámetro $inf\_citation\_count$ representa el número de citas altamente influyentes del autor \cite{valenzuela2015identifying}. $citation\_velocity$ indica lo popular que es el autor durante los últimos 3 años. $seniority$ es la cantidad de años transcurridos entre la primera y última publicación del autor. Por último, $papers$ es el número total de artículos publicados por el autor. 
Estos parámetros son extraídos de la API REST de Semantic Scholar\cite{semanticscholar2018sc} a través del Identificador Digital de Objeto (DOI, por sus siglas en inglés)\cite{paskin2010digital} del documento. Una vez que el módulo Reputation Calculator ha calculado la reputación del artículo, esta se añade a \emph{Consolidación de información de documentos}, como un atributo nuevo.

\subsection{Módulo de Gestión del conocimiento} 
\label{sec:know}
Este módulo consulta \emph{Consolidación de información de documentos} y sirviéndose de 3 submódulos, construye finalmente el lexicón. Estos 3 submódulos son Filtro de texto, Normalizador de texto y Constructor del lexicón.

\subsection{Filtro de texto} 
\label{sec:filter}

Este módulo analiza los resúmenes extraidos por el módulo ETL por cada documento, aplicando técnicas de procesamiento de lenguaje natural (NLP) \cite{jurafsky2014speech} extrayendo los sustantivos y eliminando palabras vacías \cite{chandramouli2018domain}, tanto genéricas como de dominio médico\cite{gupta2015distantly} y académico\cite{seinecleStopwords2016}. Finalmente, se obtienen los lemas de los sustantivos, lo que permite cierta desambiguación, ya que el lema de una palabra depende de la función sintáctica de la misma. Además, se resuelven posibles conflictos entre mayúsculas, minúsculas, singulares y plurales.

\subsection{Normalizador de texto} 
\label{sec:filter}
Este submódulo construye una matriz de términos por documentos \cite{anandarajan2019term} a partir de la cuál construye la matriz TF-IDF \cite{ramos2003using}. Los pesos resultantes se combinan con las reputaciones de los artículos dando la medida de relevancia de cada término $rel\_lex_{t}$. La relevancia de cada término $t$ en los  $N$ artículos pertenecientes al corpus $C$ viene dada por:

\begin{equation}
	rel\_lex_{t} =\log\left(\frac{1}{N} \cdot \sum \limits_{p=1}^N \beta  \cdot tfidf(t)_p + (1-\beta) \cdot rep_p\right), \forall p \in C \,,
\label{eq:4}
\end{equation}

donde $rep_p$ es la reputación del artículo $p$, $tfidf(t)_p$ es el valor TF-IDF del término $t$ en el artículo $p$ y $\beta \in (0,1)$ es otro parámetro que modula la importancia relativa del valor TF-IDF sobre la reputación. Cabe destacar que $tfidf(t)_p \in (0,1)$ ya que han sido normalizados por simplicidad y se aplica el logaritmo para normalizar la distribución.

\subsection{Constructor del lexicón} 
\label{sec:filter}
Este componente construye y organiza el lexicón a partir del texto normalizado. Contempla además la posibilidad de ponderar aún más el peso de aquellos términos de dominio específico proporcionados por un diccionario, médico en este caso \cite{webster2017merriam}. 

Se organizan y construyen lexicones por cada conjunto de artículos correspondientes a cada año disponible, teniendo en cuenta la evolución de la relevancia de cada término a lo largo de los años. De esta manera se puede modular la curva de olvido \cite{averell2011form} y tener en consideración las tendencias del dominio de aplicación.

Se construyen diferentes valores de relevancia para cada término específico $rel\_lex_{t}(y)$ de acuerdo a un año específico $y$, manteniendo las palabras del año anterior en el nuevo de la forma:

\begin{equation}
	rel\_lex_{t}(y) = \rho \cdot rel\_lex_{t} + (1-\rho)\cdot rel\_lex_{t}(y-1) \,,
\label{eq:5}
\end{equation}

donde $rel\_lex_{t}$ es la relevancia proporcionada por el marco de trabajo para el término $t$ y $rel\_lex_{t}(y-1)$ es la correspondiente al año anterior $y-1$. El parámetro $\rho$ controla el peso del año anterior.

\section{Creación del la red neuronal} 
\label{sec:red}

Por muy grande que sea el corpus que se utilice para la creación de los lexicones, es virtualmente imposible contar con la relevancia de todos los términos existentes. Por tanto, se ha empleado una Red Neuronal Convolucional (CNN, por sus siglas en inglés)\cite{poria2015deep} para servir de apoyo al sistema. El propósito de la red es predecir la relevancia de aquellas frases que no contengan ninguna palabra presente en el lexicón. En la Tabla \ref{tab:cnn} se puede ver la configuración de la misma, la cuál es una versión optimizada de la aproximación introducida en \cite{bhavsar2017natural}. Cabe destacar que la capa de \textit{embedding} utiliza un modelo pre-entrenado de Glove \cite{pennington2014glove} con un vocabulario de  $400,000$ palabras de  Wikipedia \cite{o2016wikipedia}. La capa de salida cuenta con activación \textit{softmax}, la cuál proporciona valores entre $0$ y $1$. En las capas ocultas se cuenta con convoluciones, funciones de activación  \textit{relu} y funciones de \textit{dropout}.

Para construir la red, se propone la siguiente metodología: En primer lugar, el usuario selecciona un conjunto de artículos del corpus que no hayan sido utilizados para construir el lexicón. Después, se  procesa el texto separando por frases y términos, eliminando palabras vacías y lematizando de manera análoga a como se procede en el módulo de ETL, de esta manera se aumenta el número potencial de coincidencias entre el texto utilizado para la creación de la red y las palabras del lexicón. Se etiquetarán como relevantes ($1$) aquellas frases con mayor relevancia de acuerdo al lexicón y como no relevantes ($0$) las de menor relevancia o aquellas que no contengan palabras del lexicón. Se define, por tanto, 
un umbral de relevancia $\epsilon$ para elegir el mínimo necesario de acuerdo a lo estricta que se quiere que sea la red neuronal. Finalmente se debe elegir el número de frases etiquetadas para conformar el conjunto de entrenamiento y test. La red neuronal resultante debería ser capaz de prececir la relevancias de las frases sin palabras del lexicón.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{c}
			\hline
			\textbf{Layers} \\
            \hline
			\multicolumn{1}{l}{1. Embedding input\_dim 400000 output\_dim 50} \\
			\multicolumn{1}{l}{2. Dropout rate 0.4} \\
			\multicolumn{1}{l}{3. Conv1D 250 filters of 3 with stride 1} \\
            \multicolumn{1}{l}{4. Pool1D (max) with stride 1} \\
            \multicolumn{1}{l}{5. Dense units 250} \\
            \multicolumn{1}{l}{6. Dropout rate 0.4} \\
            \multicolumn{1}{l}{7. Relu} \\
            \multicolumn{1}{l}{8. Dense units 1} \\
            \multicolumn{1}{l}{9. Softmax} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Capas de la red neuronal convolucional.}
	\label{tab:cnn}
\end{table}

\section{Estimación de relevancias de artículos} 
\label{sec:full_process}

Se ha diseñado un flujo de trabajo para ilustrar como funciona todo el proceso del marco de trabajo. Se comienza eligiendo un texto para evaluar y se concluye devolviendo su relevancia normalizada entre $0$ y $1$ (ver Figura. \ref{fig:arquitectura}).

\begin{figure}
  \centering
  \includegraphics[width=8cm, keepaspectratio]{img/pipeline_esp}
  \caption{Flujo de trabajo de cálculo de relevancia de un artículo}
  \label{fig:arquitectura}
\end{figure}

En primer el sistema detecta si el documento  cuya relevancia se desea conocer consiste en texto plano o un fichero (de tipo PDF, html o similar). En caso de ser un fichero, este es parseado, limpiado y partido en frases y párrafos. Estas tareas se llevan a cabo en los pasos \emph{Parsear a texto crudo} y \emph{Limpiar y tokenizar frases}, respectivamente.

Una vez se tienen mapeados los párrafos en listas de lemas de sustantivos, se consulta el lexicón por cada lista, acumulando el valor de relevancia de cada lema. En caso de que una frase no contenga ningún lema presente en el lexicón, la lista de lemas se tranforma en los vectores que entran a la red neuronal, que devuelve la predicción de relevancia. Estas tareas son llevadas a cabo por el módulo \emph{Calculador de relevancia}. Una vez recorridas todas las listas de lemas, la relevancia viene dada por la Ecuación:
\begin{equation}
	combined\_rel_{p} = \theta \cdot rel\_lex_{p} + (1-\theta) \cdot \frac{1}{K} \sum \limits_{k=1}^K rel\_neural(s_k)\,,
    \label{eq:7}
\end{equation}

donde $rel\_lex_p$ es la relevancia media del artículo proporcionada por el lexicón, $\{s_k\}_{k=1}^K$ es el conjunto de frases cuya relevancia es desconocida y $rel\_neural$ es la relevancia predicha por la red neuronal para cada $s_k$. El parámetro $\theta \in (0,1)$ modula la importancia relativa de la red neuronal.

En última instancia, en caso de que la entrada al sistema sea un documento y no texto plano, se comprueban los metadados del mismo para tratar de encontrar el DOI. En caso de estar disponible, el módulo \emph{Calculador de relevancia}, calcula su reputación y esta es utilizada para calcular la relevancia final del documento, la cuál viene dada por:

\begin{equation}
	combined\_rel\_doi_{p} = \gamma \cdot combined\_rel_{p} + (1-\gamma)\cdot rep_{p} \,,
    \label{eq:8}
\end{equation}

donde $combined\_rel_p$ es la relevancia combinada del lexicón y la red neuronal para el artículo y $rep_p$ es su reputación. El parámetro $\gamma \in (0,1)$ modula, su importancia relativa.

En caso de que el DOI no esté disponible, se devuelve el resultado de la Ecuación \ref{eq:7} como medida de relevancia final.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESULTADOS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Experimentos y resultados}
\label{chap:resus}
En este capítulo se presentan los experimentos realizados. En primer lugar se presenta un diagrama de Gantt \cite{wilson2003gantt} con la planificación temporal del desarrollo, después se detallan los  diferentes lexicones creados, después las redes neuronales y, por último, los resultados evaluando la relevancia de diversos conjuntos de documentos.
\section{Planificación temporal}
\label{sec:planificacion-temporal}
En la Figura \ref{fig:gant} se puede ver un diagrama de Gantt que ilustra el tiempo empleado en cada una de las etapas del desarrollo.
La primera parte, se corresponde con el estudio e investigación del estado del arte, el cuál ha comprendido desde el inicio hasta el final del proyecto. Después, la obtención, pre-procesado y almacenaje de los datos, lo cuál incluye parseo, limpieza, cálculo de resúmenes y reputaciones. En la fase de creación de lexicones se construyen 4 diferentes por año. De forma análoga, se crean 4 redes neuronales por año. Finalmente, se realizan diversos experimentos para evaluar el rendimiento del sistema completo.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/gantt.png}
  \caption{Diagrama de Gantt del desarrollo}
  \label{fig:gant}
\end{figure}  

\section{Descarga y preprocesado de artículos}
\label{sec:lexis} 

Siguiendo la metodología expuesta en la Sección \ref{sec:etl}, se procede a la descarga, limpieza y almacenaje de dos millones de artículos de Pubmed Central.
De los mas de dos millones de artículos descargados, todos son parseados y limpiados, pero sólo se calcula el resumen y la reputación de cuatro conjuntos de $15000$ artículos, que se corresponden con los años 2015, 2016, 2017 y 2018, para cada uno de los cuáles se construye un lexicón único. Se elige el número $15000$ porque en pruebas anteriores se ha comprobado que es el número máximo de filas de la matriz de términos por documentos que cabe en la memoria del equipo de pruebas (16GB de RAM). 
Se fijan los parámetros de modulación para cada una de las ecuaciones del cálculo de reputaciones:
En primer lugar, para la ecuación \ref{eq:1} se fija $\alpha$ a $0.5$ dando el mismo peso al número de citas que a la reputación de los coautores, ya que un alto volumen de citas es indicativo de un alto nivel de reputación, no obstante, si se le diera aún mas peso, se penalizarían demasiado los artículos mas recientes. En la ecuación \ref{eq:3} las omegas se fijan de la siguiente manera:
$\omega_1$ = 0.2, $\omega_2$ = 0.1, $\omega_3$ = 0.3, $\omega_4$ = 0.4

Se decide dar más peso a los valores de veteranía y número de artículos publicados por el autor, ya que los otros dos parámetros, son valores que, aunque tienen relevancia, cuentan con un mayor nivel de subjetividad y son calculados con algoritmos propios de Semantic Scholar.

Una vez fijados los parámetros de modulación, se fijan los valores de saturación a partir del percentil 90 de cada parámetro tomando una muestra de 5000 artículos aleatorios, ver Tabla \ref{tab:saturacion}. 

\begin{table}[]
\begin{center}

\begin{tabular}{|c|c|}
\hline
\textbf{Parámetro}       & \textbf{Saturación} \\ \hline
Número de artículos      & 196                 \\ \hline
citationVelocity         & 105                 \\ \hline
influentialCitationCount & 208                 \\ \hline
Seniority                & 34                  \\ \hline
Citas del artículo       & 10                  \\ \hline
\end{tabular}
\caption{Valores de saturación}
\label{tab:saturacion}
\end{center}
\end{table}

Al fijar los valores de saturación y normalizar entre $0$ $1$ la reputación de todos los artículos está también entre 0 y 1.

\section{Creación de lexicones por año.}
\label{sec:lex_creation}

Siguiendo la metodología propuesta en la sección \ref{sec:lex}, se fijan los parámetros para las Ecuaciones \ref{eq:4} y \ref{eq:5}:

Para la Ecuación \ref{eq:4}, se toma $\beta$ $=$ $0.5$ para dar la misma importancia a la reputación que a la componente léxica en la medida de relevancia.
En la Ecuación \ref{eq:4} se toma $\rho$ $=$ $0.8$, lo cuál da un mayor peso a la relevancia actual del término, teniendo en cuenta algo de la relevancia del año anterior. Cabe destacar, que para aquellos términos que dejen de estar presentes de un año para otro, su relevancia actual es de $(1-\rho) 0.2$. Que un término desaparezca por completo de un año para otro es indicativo de ser poco relevante y aunque se mantiene en el lexicón del año actual, su relevancia es penalizada. Por otra parte, a aquellos términos nuevos para cada lexicón (no aparecen en años anteriores) se les da toda la relevancia correspondiente, al ser considerados términos de relevancia emergente.
Por motivos obvios, el lexicón correspondiente al año 2015 no cuenta con factor de memoria de los años anteriores, ya que este actúa como semilla.

Por otra parte, se ha tenido en consideración el uso de un diccionario médico abierto para darle más peso a los términos estrictamente médicos y así penalizar la relevancia de términos de carácter académico, típicos en el lenguaje de todos los artículos de investigación. En concreto, los mejores resultados se han obtenido dándole un 80 por ciento del peso a aquellos términos del diccionario médico y el resto a los que no están. Esto provoca una separación en la poblaciones claramente visible en los histogramas de las relevancias de los lexicones (ver Figura \ref{fig:hists}). Conforme se aumenta de año, puede verse un ensanchamiento de la población de los términos que se encuentran en el diccionario, fruto de la adición de los términos de años anteriores.

\begin{figure}[htbp]
\centering
\subfigure[2015]{\includegraphics[width=65mm]{img/2015_hist.png}}
\subfigure[2016]{\includegraphics[width=65mm]{img/2016_hist.png}}
\subfigure[2017]{\includegraphics[width=65mm]{img/2017_hist.png}}
\subfigure[2018]{\includegraphics[width=65mm]{img/2018_hist.png}}
\caption{Histograma de relevancias para cada lexicón.} \label{fig:hists}
\end{figure}


\section{Creación de las redes neuronales por año.}
\label{sec:lexis}

Para crear el conjunto de entrenamiento, se cuenta con mas de $100000$ artículos de cada año no utilizados para la creación de los lexicones. Siguiendo el procedimiento descrito en la Sección \ref{sec:red}, se crea un conjunto con $320000$ frases etiquetadas para entrenamiento y $80000$ para test para los 4 lexicones. Se etiquetan como relevantes aquellas frases que contienen 4 o más sustantivos que tengan relevancia $0.7$ o mayor. Se utiliza este valor de corte porque es a partir del cuál se encuentra la mayoría de los términos mas relevantes de la población perteneciente al diccionario médico. Siguiendo este criterio, se realiza un análisis exploratorio con $1000$ artículos del año 2015 no utilizados para la creación del lexicón, obteniendo los siguientes resultados:
$112808$ frases totales analizadas, de las cuáles $96682$ son etiquetadas como relevantes y   $16126$ como no relevantes. El alto porcentaje de frases relevantes indica que el lexicón tiene una riqueza aceptable, implicando una menor dependenencia de la red neuronal.

Se ha probado con dos conjuntos pre-entrenados de \emph{Word2vec} \cite{goldberg2014word2vec} uno de Google y otro de Glove \cite{pennington2014glove}. En el caso del Modelo de Google, el cuál cuenta con un diccionario de $3000000$ palabras, se ha analizado el conjunto de completo de entrenamiento y test del año 2015, en el cuál hay un total de $5026862$ sustantivos, de los cuáles $4809398$ se encuentran en el diccionario de Word2Vec. Cuenta con $97104$ sustantivos únicos de los cuáles $34203$ se tienen codificados. Dado el elevado volumen de palabras codificadas en la capa de \textit{embeddings} utilizando este modelo, el modelo final de predicción de relevancia ocupa 3,6GB en disco.

Por otra parte, el modelo de Glove, el cuál cuenta con $400000$ palabras codificadas. Del total del mismo conjunto del $2015$, hay $4826158$ en el diccionario, siendo superior al modelo de Google a pesar de contar este último con más palabras codificadas. En cuanto a sustantivos únicos, se encuentran un total de $34203$, de nuevo, superior al modelo de Google, que además da lugar a modelos entrenados mucho mas ligeros, de 80MB en disco, por tanto se elige trabajar con el modelo de Glove. En la Tabla \ref{tab:red_tests} pueden verse los porcentajes de acierto con los conjuntos de test para cada año.

\begin{table}[]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\textbf{Año}       & \textbf{Acierto en conjunto de test} \\ \hline
2015      	& $0.964$                \\ \hline
2016        & $0.962$                 \\ \hline
2017 		& $0.959$                 \\ \hline
2018        & $0.959$                  \\ \hline
\end{tabular}
\caption{Resultados de test de las redes neuronales}
\label{tab:red_tests}
\end{center}
\end{table}

\section{Experimentos}
\label{sec:lexis}

Se han analizado un total de $8000$ artículos con el sistema completo, $2000$ para cada año, prediciendo los artículos de cada año con el lexicón y la red del año anterior, a excepción de los artículos del año 2015, para los cuáles se ha utilizado la red y el lexicón del mismo año.
Se ha calculado la relevancia con los siguientes parámetros:
En la Ecuación \ref{eq:7}, se toma $\theta$ = $0.8$ dando la mayor parte del peso a la parte del lexicón, ya que la red funciona como apoyo al sistema.
Por otra parte, en la Ecuación \ref{eq:8} se toma $\gamma$ = $0.6$ dando la mayor parte del peso al resultado de la Ecuación \ref{eq:7}.
En la Figura \ref{fig:2016_results} se puede ver una representación de variables dos a dos de los resultados de predicción del año $2016$ con la red y el lexicón del $2015$. 

Puede observarse la poca influencia que tienen los valores de reputación de la red neuronal sobre la relevancia total del sistema incluyendo la reputación, lo cuál es indicativo de que las frases cuya relevancia se desconoce tienen poca relevancia (buen funcionamiento de la red) que a su vez es consecuencia del buen funcionamiento del lexicón, ya que cerca del 90 porciento de las frases tienen relevancia conocida.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/2016_results_mod.png}
  \caption{Resultados 2016}
  \label{fig:2016_results}
\end{figure}  

Aunque se han analizado documentos para los siguientes años, de las gráficas se extraen las mismas conclusiones, ya que tienen distribuciones muy parecidas.

Por otra parte, en la Figura \ref{fig:rel_tab} puede verse una tabla con los $15$ resultados de mayor relevancia del caso anterior. En en todos los casos, los valores de reputación son elevados, lo que está también acorde con lo elevados que son los valores de la puntuación del lexicón exclusivamente. En todos los casos el valor de relevancia proporcionado por la red neuronal es muy baja o oncluso $0$, reforzando el carácter de apoyo de las red neuronal.
En todos los casos se trata de artículos de gran impacto y número de citas, tendencia que se mantiene en la gran mayoría de artículos de alta reputación. En aquellos casos en los se tiene un elevado valor en la relevancia pero bajo número de citas o reputación en general, se debe a un muy elevado valor de la componente exclusivamente léxica, no obstante, es un comportamiento raramente dado.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/kib1.png}
  \caption{artículos analizados de mayor relevancia}
  \label{fig:rel_tab}
\end{figure}  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones}
\label{chap:conclusiones}

En cuanto a la consecución de los objetivos específicos, se puede decir que se han conseguido con éxito. Se ha obtenido un volumen de artículos más que suficiente para los experimentos, el desarrollo y trabajos futuros. Se han creado los lexicones y las redes neuronales, cuyo rendimiento ha sido evaluado por separado y en conjunto con resultados satisfactorios. El resultado final ofrece un marco de trabajo completo de fácil uso, bajo coste computacional (una vez entrenado) y de fácil reproducción si se desea aplicar a otro dominio.  

Quedan, no obstante, para trabajos futuros la detección de correferencias de términos, lo que daría una componente frecuencial de éstos más precisa. También quedaría pendiente el entrenamiento y aplicación de embeddings creados con el propio corpus de entrenamiento, ya que como se ha visto en capítulo anterior, el conjunto de entrenamiento tiene un gran número de palabras para las que no se cuenta con represetacíon vectorial. Otra posible línea de mejora, consiste en sustituir la utilización de uni-gramas por la de n-gramas con conceptos del dominio de aplicación, en el caso del dominio médico, se podría utilizar una ontología como UMLS \cite{verspoor2005towards}. Esto plantearía, no obstante, otros desafíos, como la detección de conceptos y la desambiguación de los mismos dentro de los textos.
Por último, aunque los lexicones han demostrado tener una alta cantidad de los términos más relevantes, su tamaño está limitado por el equipo de pruebas y podría aumentarse si distribuye el cálculo de los mismos o se aumenta la memoria del computador encargado de construirlos, con la consecuente disminución de dependencia de la red neuronal.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

% Las siguientes dos instrucciones es todo lo que necesitas
% para incluir las citas en la memoria
\bibliographystyle{unsrt}
\bibliography{memoria}  % memoria.bib es el nombre del fichero que contiene
% las referencias bibliográficas. Abre ese fichero y mira el formato que tiene,
% que se conoce como BibTeX. Hay muchos sitios que exportan referencias en
% formato BibTeX. Prueba a buscar en http://scholar.google.com por referencias
% y verás que lo puedes hacer de manera sencilla.
% Más información: 
% http://texblog.org/2014/04/22/using-google-scholar-to-download-bibtex-citations/

\end{document}
