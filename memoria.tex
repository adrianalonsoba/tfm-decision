%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Plantilla de memoria en LaTeX para la ETSIT - Universidad Rey Juan Carlos
%%
%% Por Gregorio Robles <grex arroba gsyc.urjc.es>
%%     Grupo de Sistemas y Comunicaciones
%%     Escuela Técnica Superior de Ingenieros de Telecomunicación
%%     Universidad Rey Juan Carlos
%% (muchas ideas tomadas de Internet, colegas del GSyC, antiguos alumnos...
%%  etc. Muchas gracias a todos)
%%
%% La última versión de esta plantilla está siempre disponible en:
%%     https://github.com/gregoriorobles/plantilla-memoria
%%
%% Para obtener PDF, ejecuta en la shell:
%%   make
%% (las imágenes deben ir en PNG o JPG)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper, 12pt]{book}
%\usepackage[T1]{fontenc}

\usepackage[a4paper, left=2.5cm, right=2.5cm, top=3cm, bottom=3cm]{geometry}
\usepackage{times}
\usepackage[latin1]{inputenc}
%\usepackage[spanish]{babel} % Comenta esta línea si tu memoria es en inglés
\usepackage[spanish,es-tabla]{babel}
\usepackage{url}
%\usepackage[dvipdfm]{graphicx}
\usepackage{graphicx}
\usepackage{float}  %% H para posicionar figuras
\usepackage[nottoc, notlot, notlof, notindex]{tocbibind} %% Opciones de índice
\usepackage{latexsym}  %% Logo LaTeX

\usepackage{graphicx} % figuras
\usepackage{subfigure} % subfiguras

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\title{Marco de trabajo para evaluar la relevancia de los artículos en el dominio científico}
\author{Adrián Alonso Barriuso}

\renewcommand{\baselinestretch}{1.5}  %% Interlineado

\begin{document}

\renewcommand{\refname}{Bibliografía}  %% Renombrando
\renewcommand{\appendixname}{Apéndice}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PORTADA

\begin{titlepage}
\begin{center}
\begin{tabular}[c]{c c}
%\includegraphics[bb=0 0 194 352, scale=0.25]{logo} &
\includegraphics[scale=0.25]{img/logo_vect.png} &
\begin{tabular}[b]{l}
\Huge
\textsf{UNIVERSIDAD} \\
\Huge
\textsf{REY JUAN CARLOS} \\
\end{tabular}
\\
\end{tabular}

\vspace{3cm}

\Large
MÁSTER EN INGENIERÍA EN SISTEMAS DE DECISIÓN

\vspace{0.4cm}

\large
Curso Académico 2018/2019

\vspace{0.8cm}

Trabajo Fin de Máster

\vspace{2.5cm}

\LARGE
Marco de trabajo para evaluar la relevancia de los artículos en el dominio científico

\vspace{4cm}

\large
Autor : Adrián Alonso Barriuso \\
Tutor : Dr. Alberto Fernández Isabel

\end{center}
\end{titlepage}

\newpage
\mbox{}
\thispagestyle{empty} % para que no se numere esta pagina

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Dedicatoria

\chapter*{}
\pagenumbering{arabic}

\begin{flushright}
\textit{Dedicado a \\
mi sobrino, Alberto, algún día te explicaré todo esto....}
\end{flushright}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Agradecimientos

\chapter*{Agradecimientos}
%\addcontentsline{toc}{chapter}{Agradecimientos} % si queremos que aparezca en el índice
\markboth{AGRADECIMIENTOS}{AGRADECIMIENTOS} % encabezado 

Gracias a mi familia y amigos por estar ahí cuando había que estar. Gracias a todos los compañeros del DSLAB por vuestra ayuda e inspiración, mención especial para Isaac. Gracias a Medlab Media Group y a mi tutor, Alberto, por vuestra confianza y apoyo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen

\chapter*{Resumen}
%\addcontentsline{toc}{chapter}{Resumen} % si queremos que aparezca en el índice
La comunidad investigadora se enfrenta cada vez a un mayor número de publicaciones y tendencias que deben atender a la hora hacer sus propias publicaciones. Estos tópicos y tendencias  son estado del arte en el momento de su publicación o presentación en conferencias, no obstante, pueden perder relevancia con el paso del tiempo. Esta medida de relevancia de publicaciones representa un desafío para la comunidad investigadora, la cuál invierte mucho tiempo leyendo literatura a menudo desfasada o poco relevante. Para abordar este problema, se introduce un marco de trabajo para evaluar la relevancia de artículos científicos a través de, principalmente, un lexicón y una red neuronal. Se han llevado a cabo diversos experimentos aplicados al dominio de la medicina que demuestran el buen funcionamiento del marco de trabajo.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Resumen en inglés

\chapter*{Summary}
%\addcontentsline{toc}{chapter}{Summary} % si queremos que aparezca en el índice
\markboth{SUMMARY}{SUMMARY} % encabezado
The research community is faced with an increasing number of publications and trends that need to be taken into account when making their own publications. These topics and trends are state of the art at the time of publication or presentation at conferences, however, they may lose relevance over time. This measure of publication relevance represents a challenge for the research community, which spends a lot of time reading often outdated or irrelevant literature. To address this problem, a framework is introduced to assess the relevance of scientific articles primarily through a lexicon and neural network. Several experiments applied to the field of medicine have been carried out that demonstrate the good performance of the framework.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ÍNDICES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Las buenas noticias es que los índices se generan automáticamente.
% Lo único que tienes que hacer es elegir cuáles quieren que se generen,
% y comentar/descomentar esa instrucción de LaTeX.

%%%% Índice de contenidos
\tableofcontents 
%%%% Índice de figuras
\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de figuras} % para que aparezca en el indice de contenidos
\listoffigures % indice de figuras
%%%% Índice de tablas
%\cleardoublepage
%\addcontentsline{toc}{chapter}{Lista de tablas} % para que aparezca en el indice de contenidos
%\listoftables % indice de tablas


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INTRODUCCIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Introducción}
\label{sec:intro} % etiqueta para poder referenciar luego en el texto con ~
En este capítulo introductorio se presenta, en primer lugar, el contexto científico sobre el que se enmarca el presente proyecto. Después, se introduce el objetivo principal y finalmente los objetivos específicos.

\section{Contexto}
\label{sec:contexto}

La comunidad investigadora invierte la mayor parte de su tiempo  documentándose, investigando literatura previa y el estado del arte. A menudo, la relevancia de los diferentes tópicos sobre los que se investiga fluctúa en gran medida con el tiempo, lo que provoca que a menudo los investigadores pierdan mucho tiempo con literatura desfasada o poco relevante. Por tanto, este trabajo introduce un marco de trabajo completo que tiene como finalidad organizar y medir la relevancia de artículos de investigación.

Dado que se trabaja con información textual, se utilizan técnicas de Procesamiento de Lenguaje Natural (NLP, por sus siglas en inglés) \cite{jurafsky2014speech} que sirven para poder tratar con este tipo de información desde un punto de vista computacional. A través de estas técnicas, las cuáles se combinan con métricas de reputación \cite{josang2007survey}, se construye un lexicón de relevancias para evaluar la relevancia de los documentos de un modo similar a un análisis de sentimientos \cite{de2018visual}. Para complementar este lexicón, se emplean técnicas de Deep Learning \cite{lecun2015deep} para evaluar la relevancia de los términos cuya relevancia sea desconocida por el lexicón.

\subsection{Dominio de aplicación}
\label{sec:dominio}

Aunque este marco de trabajo puede ser entrenado para cualquier dominio de investigación científica, los experimentos se han llevado a cabo en el dominio médico. Se han descargado y parseado mas de dos millones de artículos de investigación médica provenienyes de Pubmed Central . Cabe destacar que, aunque los artículos de investigacion podrían ser considerados un dominio de aplicación por si mismo, la ciencia abarca demasiados temas para que el sistema funciona de forma deseable, por tanto, el sistema sólo debe ser utilizado apra evaluar los documentos del mismo dominio de aplicación concreto con el que haya sido entrenado.



\section{Objetivos}
\label{sec:objetivos}

El principal objetivo del presente trabajo es la creación del sistema completo de evaluación de relevancias, lo que comprende un marco de trabajo que incluye la interfaz para la introducción de documentos y a la salida devuelva la relevancia de los mismos.

\subsection{Objetivos específicos}
\label{sec:obepescificos}

\begin{itemize}
\item Obtención del corpus de documentos científicos: Se necesita un gran volumen de documentos para la creación del lexicón, el entrenamiento de la red neuronal y para la validación del sistema. 
\item Limpieza y almacenaje de los documentos: Una vez descargados, deben ser limpiados y debidamente almacenados en base de datos. Se almacenan con los metadatos necesarios para la creación del lexicón y la red neuronal, como la fecha, el DOI, el resumen y la reputación de cada artículo.
\item Construcción del lexicón de relevancias: Se aplican diversas métricas para la creación del lexicón. A mayor volumen de documentos utilizado, mayor riqueza y precisión del lexicón, lo que implica una menor dependencia de la red neuronal.
\item Construcción de la red neuronal: Debido a las limitaciones del lexicón, ya sea por limitaciones computacionales o de volumen de corpus considerado, se crea una red neuronal de apoyo para predecir las relevancias fuera del lexicón.
\item Creación del flujo de evaluación de relevancia: Se analizan documentos o textos nuevos combinando las métricas de relevancia proporcionadas por el lexicón, la red neuronal y la reputación para estimar la relevancia de los mismos.
\end{itemize}

\section{Estructura de la memoria}
\label{sec:estructura}

La memoria tiene los siguientes capítulos fundamentales:

\begin{enumerate}
\item Introducción.
\item Estado del arte: En este capítulo se revisa la literatura en la que se apoya el siguiente trabajo, explicando ideas utilizadas y otras descartadas
\item Propuesta: Se trata del capítulo central y más importante, en el cuál se describe la propuesta del marco de trabajo completo.
\item Experimentos y resultados: Se describe el caso uso del marco de trabajo, presentando los diferentes experimentos realizados.
\item Conclusiones: En este capítulo final se evalúan los resultados obtenidos y objetivos completados. También se revisan posibles líneas futuras de investigación y mejora.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ESTADO DEL ARTE %el
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Estado del arte}


\section{Algoritmos de reputación}
\label{sec:alrepus}


\section{Obtención de relevancias}
\label{sec:oreles}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DISEÑO E IMPLEMENTACIÓN %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Propuesta}
\label{chap:propuesta}
En este capítulo, se describe la propuesta del sistema completo, definiendo entradas y salidas explicadas a nivel de diseño. Se empieza con una subsección donde se ve la arquitectura y el propósito general y después se entra en detalle para cada uno de los módulos en las subsiguientes secciones.

\section{Arquitectura general} 
\label{sec:arquitectura}
En la Figura \ref{fig:arquitectura}, se pueden observar el módulo principal: \textit{Relevance estimator module}, que es el encargado de estimar las relevancias de los artículos de entrada, y sus correspondientes submódulos: \textit{Text processor, Reputation calculator y Relevance calculator}. Se cuenta además, con dos fuentes de información precalculadas utilizadas por el submódulo \textit{Relevance calculator}, a saber, \textit{Relevance lexicon} que consiste en cuatro lexicones\cite{pustejovsky1991generative} de relevancias de términos médicos y \textit{Neural network}, que consiste en cuatro modelos entrenados de redes neuronales convolucionales (CNN)\cite{poria2015deep} por sus siglas en inglés. Por otra parte, se cuenta con un módulo de visualización(\textit{Visualization}), que se utiliza para ver la salida del sistema y para proporcionar la entrada (\textit{Text}). Por último, se utiliza una fuente de información externa en tiempo real (\textit{Web information resources}).

En primer lugar se entra en detalle en cómo se construye Relevance lexicon, después Neural network y, por último, Relevance estimator module, el cuál emplea todo lo anterior para calcular las relevancias de nuevos documentos.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/architecture}
  \caption{Arquitectura general}
  \label{fig:arquitectura}
\end{figure}

\section{Creación del lexicón de relevancias} 
\label{sec:lex}
El lexicón de relevancias tiene un papel fundamental a la hora de estimar la relevancia de los artículos, en concreto, contiene la relevancia de las palabras de el dominio de aplicación utilizado para crear el mismo. Para la creación del lexicón se ha diseñado un marco de trabajo completo, cuya arquitectura puede verse en la Figura \ref{fig:train_lexicon}. Esta cuenta con un módulo de extracción, transformación y carga (ETL por sus siglas en inglés)\cite{vassiliadis2009survey}, un módulo de gestión de conomicimiento (Knowledge managment) y uno de visualización. Se cuenta, además, con dos bases de datos, una orientada a documentos\cite{han2011survey}(Document knowledge consolidation) y una ElasticSearch\cite{gormley2015elasticsearch} para visualización con Kibana \cite{gupta2015kibana}.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/train_lexicon}
  \caption{Arquitectura de generación de lexicones}
  \label{fig:arquitectura}
\end{figure}

\subsection{Módulo ETL} 
\label{sec:etl}

El módulo ETL se encarga de la obtención y el preprocesado del corpus de artículos médicos. Se divide a su vez en dos submódulos: Corpus processor y Reputation calculator.
Corpus processor obtiene artículos de Pubmed Central\footnote{\url{https://www.ncbi.nlm.nih.gov/pmc/}} utilizando técnicas de web scrapping \cite{mitchell2018web}. Estos artículos en formato XML \cite{bray2000extensible}, son parseados y almacenados en formato JSON \cite{crockford2006application} en Document knowledge consolidation con una estructura de párrafos y frases, eliminando tablas, gráficas u otros artefactos no aprovechables por el sistema.
Una vez un documento se almacena en la base de datos, se procede a calcular su resumen automático aplicando el clásico algoritmo Text Rank \cite{mihalcea2004textrank} utilizando una popular implementación en Python \cite{DBLP:journals/corr/BarriosLAW16}. Este tipo de resúmenes ofrecen una ordenación de las frases de un documento por relevancia, sirviendo como factor de filtrado de información poco relevante o redundante y a la vez como factor de compresión, haciendo la información más manejable en memoria. Se obtiene un 20 porciento del tamaño original de los artículos y se almacena como un nuevo artibuto del documento en la base de datos.

Una vez preprocesados y almacenados los artículos, emph{Reputation calculator} calcula la reputación de los mismos para que esta sea añadida como nuevo atributo y ser utilizada posteriormente por el módulo Knowledge managment.
El algoritmo de reputación empleado es una adaptación del introducido en el artículo \cite{fernandez2018unified}. La reputación a priori de un artículo viene dada por:
\begin{equation}
\label{eq:1}
	rep_{p} = \alpha \cdot rep\_authors_{p} + (1 - \alpha) \cdot citations_{p} \,,
\end{equation}

donde  $rep\_authors_{p}$ es la reputación media del los autores del artículo y $citations_{p}$ su número de citas total en el momento de la consulta. El parámetro $\alpha \in (0,1)$ actúa como modulador de importancia relativa entre las citas y los autores. La reputación de cada autor viene dada por:
\begin{equation}
\label{eq:3}
	rep_{i} = \omega_1 \cdot inf\_citation\_count + \omega_2 \cdot citation\_velocity + \omega_3 \cdot seniority + \omega_4 \cdot papers \,,
\end{equation}

donde $\sum_{i=1}^4\omega_i=1$. El parámetro $inf\_citation\_count$ representa el número de citas altamente influyentes del autor. \cite{valenzuela2015identifying}. $citation\_velocity$ indica lo popular que es el autor durante los últimos 3 años. $seniority$ es la cantidad de años transcurridos entre la primera y última publicación del autor. Por último, $papers$ es el número total de artículos publicados por el autor. 
Estos parámetros son extraídos de  la API REST de Semantic Scholar\cite{semanticscholar2018sc} a través del Identificador Digital de Objeto (DOI, por sus siglas en inglés)\cite{paskin2010digital} del documento. Una vez que el módulo Reputation Calculator ha calculado la reputación del artículo, esta se añade a \emph{Document knowledge consolidation}, como un atributo nuevo.

\subsection{Módulo de Gestión del conocimiento} 
\label{sec:know}
Este módulo consulta \emph{Document knowledge consolidation} y sirviéndose de 3 submódulos, construye finalmente el lexicón. Estos 3 submódulos son Text filter, Text normalizer y Lexicon builder.

\subsection{Text filter} 
\label{sec:filter}

Este módulo analiza los resúmenes extraidos por el módulo ETL por cada documento, aplicando técnicas de procesamiento de lenguaje natural (NLP) \cite{jurafsky2014speech} extrayendo los sustantivos y eliminando palabras vacías \cite{chandramouli2018domain}, tanto genéricas como de dominio médico\cite{gupta2015distantly} y académico\cite{seinecleStopwords2016}. Finalmente, se obtienen los lemas de los sustantivos, lo que permite cierta desambiguación, ya que el lema de una palabra depende de la función sintáctica de la misma. Además, se resuelven posibles conflictos entre mayúsculas, minúsculas, singulares y plurales.

\subsection{Text normalizer} 
\label{sec:filter}
Este submódulo construye una matriz de términos por documentos \cite{anandarajan2019term} a partir de la cuál construye la matriz TF-IDF \cite{ramos2003using}. Los pesos resultantes se combinan con las reputaciones de los artículos dando la medida de relevancia de cada término $rel\_lex_{t}$. La relevancia de cada término $t$ en los  $N$ artículos pertenecientes al corpus $C$ viene dada por:

\begin{equation}
	rel\_lex_{t} =\log\left(\frac{1}{N} \cdot \sum \limits_{p=1}^N \beta  \cdot tfidf(t)_p + (1-\beta) \cdot rep_p\right), \forall p \in C \,,
\label{eq:4}
\end{equation}

donde $rep_p$ es la reputación del artículo $p$, $tfidf(t)_p$ es el valor TF-IDF del término $t$ en el artículo $p$ y $\beta \in (0,1)$ es otro parámetro que modula la importancia relativa del valor TF-IDF sobre la reputación. Cabe destacar que $tfidf(t)_p \in (0,1)$ ya que han sido normalizados por simplicidad y se aplica el logaritmo para normalizar la distribución.

\subsection{Lexicon builder} 
\label{sec:filter}
Este componente construye y organiza el lexicón a partir del texto normalizado. Contempla además la posibilidad de ponderar aún más el peso de aquellos términos de dominio específico proporcionados por un diccionario, médico en este caso \cite{webster2017merriam}. 

Se organizan y construyen lexicones por cada conjunto de artículos correspondientes a cada año disponible, teniendo en cuenta la evolución de la relevancia de cada término a lo largo de los años. De esta manera se puede modular la curva de olvido \cite{averell2011form} y tener en consideración las tendencias del dominio de aplicación.


Se construyen diferentes valores de relevancia para cada término específico $rel\_lex_{t}(y)$ de acuerdo a un año específico $y$, manteniendo las palabras del año anterior en el nuevo de la forma:

\begin{equation}
	rel\_lex_{t}(y) = \rho \cdot rel\_lex_{t} + (1-\rho)\cdot rel\_lex_{t}(y-1) \,,
\label{eq:5}
\end{equation}

donde $rel\_lex_{t}$ es la relevancia proporcionada por el marco de trabajo para el término $t$ y $rel\_lex_{t}(y-1)$ es la correspondiente al año anteruir $y-1$. El parámetro $\rho$ controla el peso del año anterior.

\section{Creación del la red neuronal} 
\label{sec:red}

Por muy grande que sea el corpus que se utilice para la creación de los lexicones, es virtualmente imposible contar con la relevancia de todos los términos existentes. Por tanto, se ha desarrollado una Red Neuronal Convolucional (CNN, por sus siglas en inglés)\cite{poria2015deep} para servir de apoyo al sistema. El propósito de la red es predecir la relevancia de aquellas frases que no contengan ninguna palabra presente en el lexicón. En la Tabla \ref{tab:cnn} se puede ver la configuración de la misma, la cuál es una versión optimizada de la aproximación introducida en \cite{bhavsar2017natural}. Cabe destacar que la capa de \textit{embedding} utiliza un modelo pre-entrenado de Glove \cite{pennington2014glove} con un vocabulario de  $400,000$ palabras de  Wikipedia \cite{o2016wikipedia}. La capa de salida cuenta con activación \textit{softmax}, la cuál proporciona valores entre $0$ y $1$. En las capas ocultas se cuenta con convoluciones, funciones de activación  \textit{relu} y funciones de \textit{dropout}.

Para construir la red, se propone la siguiente metodología: En primer lugar, el usuario selecciona un conjunto de artículos del corpus que no hayan sido utilizados para construir el lexicón. Después, se  procesa el texto separando por frases y términos, eliminando palabras vacías y lematizando de manera análoga a como se procede en el módulo de ETL, de esta manera se aumenta el número potencial de coincidencias entre el texto utilizado para la creación de la red y las palabras del lexicón. Se etiquetarán como relevantes ($1$) aquellas frases con mayor relevancia de acuerdo al lexicón y como no relevantes ($0$) las menor relevancia o aquellas que no contengan palabras del lexicón. Se define, por tanto, 
un umbral de relevancia $\epsilon$ para elegir el mínimo necesario de acuerdo a lo estricta que se quiere que sea la red neuronal. Finalmente se debe elegir el número de frases etiquetadas para conformar el conjunto de entrenamiento y test. La red neuronal resultante debería ser capaz de prececir la relevancias de las frases sin palabras del lexicón.
\begin{table}[H]
	\begin{center}
		\begin{tabular}{c}
			\hline
			\textbf{Layers} \\
            \hline
			\multicolumn{1}{l}{1. Embedding input\_dim 400000 output\_dim 50} \\
			\multicolumn{1}{l}{2. Dropout rate 0.4} \\
			\multicolumn{1}{l}{3. Conv1D 250 filters of 3 with stride 1} \\
            \multicolumn{1}{l}{4. Pool1D (max) with stride 1} \\
            \multicolumn{1}{l}{5. Dense units 250} \\
            \multicolumn{1}{l}{6. Dropout rate 0.4} \\
            \multicolumn{1}{l}{7. Relu} \\
            \multicolumn{1}{l}{8. Dense units 1} \\
            \multicolumn{1}{l}{9. Softmax} \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Capas de la red neuronal convolucional.}
	\label{tab:cnn}
\end{table}

\section{Estimación de relevancias de artículos} 
\label{sec:full_process}

Se ha diseñao un flujo de trabajo para ilustrar como funciona todo el proceso del marco de trabajo. Se comienza eligiendo un texto para evaluar y se concluye devolviendo su relevancia normalizada entre $0$ y $1$ (ver Figura. \ref{fig:pipeline}).

\begin{figure}
  \centering
  \includegraphics[width=8cm, keepaspectratio]{img/pipeline_2}
  \caption{Flujo de trabajo de cálculo de relevancia de un artículo}
  \label{fig:arquitectura}
\end{figure}

En primer el sistema detecta si el documento  cuya relevancia se desea conocer consiste en texto plano o un fichero (de tipo PDF, html o similar). En caso de ser un fichero, este parseado, limpiado y partido en frases y párrafos. Estas tareas se llevan a cabo en los pasos \emph{Parse to raw text} y \emph{Clean and tokenize sentences}, respectivamente.

Una vez se tienen mapeados los párrafos en listas de lemas de sustantivos, se consulta el lexicón por cada lista, acumulando el valor de relevancia de cada lema. En caso de que una frase no contenga ningún lema presente en el lexicón, la lista de lemas se tranforma en los vectores que entran a la red neuronal, que devuelve la predicción de relevancia. Estas tareas son llevadas a cabo por el módulo \emph{Relevance calculator}. Una vez recorridas todas las listas de lemas, la relevancia viene dada por la Ecuación:
\begin{equation}
	combined\_rel_{p} = \theta \cdot rel\_lex_{p} + (1-\theta) \cdot \frac{1}{K} \sum \limits_{k=1}^K rel\_neural(s_k)\,,
    \label{eq:7}
\end{equation}

donde $rel\_lex_p$ es la relevancia media del artcículo proporcionada por el lexicón, $\{s_k\}_{k=1}^K$ es el conjunto de frases cuya relevancia es desconocida y $rel\_neural$ es la relevancia predicha por la red neuronal para cada $s_k$. El parámetro $\theta \in (0,1)$ parameter modula la importancia relativa de la red neuronal.

En última instancia, en caso de que la entrada al sistema sea un documento y no texto plano, se comprueban los metadados del mismo para tratar de encontrar el DOI. En caso de estar disponible, el módulo \emph{Relevance calculator}, calcula su reputaciñón y esta es utilizada para calcular la relevancia final del documento, la cuál viene dada por:

\begin{equation}
	combined\_rel\_doi_{p} = \gamma \cdot combined\_rel_{p} + (1-\gamma)\cdot rep_{p} \,,
    \label{eq:8}
\end{equation}

donde $combined\_rel_p$ es la relevancia combinada del lexicón y la red neuronal para el artcículo y $rep_p$ es su reputación. El parámetro $\gamma \in (0,1)$ modula, su importancia relativa.

En caso de que el DOI no esté disponible, se devuelve el resultado de la Ecuación \ref{eq:7} como medida de relevancia final.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% RESULTADOS %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Experimentos y resultados}
\label{chap:resus}
En este capítulo se presentan los experimentos realizados. En primer lugar se presenta un diagrama de Gantt con la planificación temporal del desarrollo, después se detallan los  diferentes lexicones creados, después las redes neuronales y, por último, los resultados evaluando la relevancia de diversos conjuntos de documentos.
\section{Planificación temporal}
\label{sec:planificacion-temporal}
En la Figura \ref{fig:gant} se puede ver un diagrama de Gantt\cite{wilson2003gantt} que ilustra el tiempo empleado en cada una de las etapas del desarrollo.
La primera parte, se corresponde con el estudio e investigación del estado del arte, el cuál ha comprendido desde el inicio hasta el final del proyecto. Después, la obtención, pre-procesado y almacenaje de los datos, lo cuál incluye parseo, limpieza, cálculo de resúmenes y reputaciones. En la fase de creación de lexicones se construyen 4 diferentes por año. De forma análoga, se crean 4 redes neuronales por año. Finalmente, se realizan diversos experimentos para evaluar el rendimiento del sistema completo.

\begin{figure}
  \centering
  \includegraphics[width=16cm, keepaspectratio]{img/gantt.png}
  \caption{Diagrama de Gantt del desarrollo}
  \label{fig:gant}
\end{figure}  

\section{Descarga y preprocesado de artículos}
\label{sec:lexis} 

Siguiendo la metodología expuesta en la sección \ref{sec:etl}, se procede a la descarga, limpieza y almacenaje de dos millones de artículos de Pubmed Central.
De los mas de dos millones de artículos descargados, todos son parseados y limpiados, pero sólo se calcula el resumen y la reputación de cuatro conjuntos de $15000$ artículos, que se corresponden con los años 2015, 2016, 2017 y 2018, para cada uno de los cuáles se construye un lexicón único. Se elige el número $15000$ porque en pruebas anteriores se ha comprobado que es el número máximo de filas de la matriz de términos por documentos que cabe en la memoria del equipo de pruebas (16GB de RAM). 
Se fijan los parámetros de modulación para cada una de las ecuaciones del cálculo de reputaciones:
En primer lugar, para la ecuación \ref{eq:1} se fija $\alpha$ a $0.5$ dando el mismo peso al número de citas que a la reputación de los coautores, ya que un alto volumen de citas es indicativo de un alto nivel de reputación, no obstante, si se le diera aún mas peso, se penalizarían demasiado los artículos mas recientes. En la ecuación \ref{eq:3} las omegas se fijan de la siguiente manera:
$\omega_1$ = 0.2, $\omega_2$ = 0.1, $\omega_3$ = 0.3, $\omega_4$ = 0.4

Se decide dar más peso a los valores de veteranía y número de artículos publicados por el autor, ya que los otros dos parámetros, son valores que, aunque tienen relevancia, cuentan con un mayor nivel de subjetividad.

Una vez fijados los parámetros de modulación, se fijan los valores de saturación a partir del percentil 90 de cada parámetro tomando una muestra de 5000 artículos aleatorios, ver Tabla \ref{tab:saturacion}. 

\begin{table}[]
\begin{center}

\begin{tabular}{|c|c|}
\hline
\textbf{Parámetro}       & \textbf{Saturación} \\ \hline
Número de artículos      & 196                 \\ \hline
citationVelocity         & 105                 \\ \hline
influentialCitationCount & 208                 \\ \hline
Seniority                & 34                  \\ \hline
Citas del artículo       & 10                  \\ \hline
\end{tabular}
\caption{Valores de saturación}
\label{tab:saturacion}
\end{center}
\end{table}

Al fijar los valores de saturación y normalizar en $0$ $1$ la reputación de todos los artículos está también entre 0 y 1.

\section{Creación de lexicones por año.}
\label{sec:lex_creation}

Siguiendo la metodología propuesta en la sección \ref{sec:lex}, se fijan los parámetros para las Ecuaciones \ref{eq:4} y \ref{eq:5}:

Para la Ecuación \ref{eq:4}, se toma $\beta$ $=$ $0.5$ para dar la misma importancia a la reputación que a la componente léxica en la medida de relevancia.
En la Ecuación \ref{eq:4} se toma $\rho$ $=$ $0.8$, lo cuál da un mayor peso a la relevancia actual del término, teniendo en cuenta algo de la relevancia del año anterior. Cabe destacar, que para aquellos términos que dejen de estar presentes de un año para otro, su relevancia actual es de $(1-\rho) 0.2$. Que un término desaparezca por completo de un año para otro es indicativo de ser poco relevante y aunque se mantiene en el lexicón del año actual, su relevancia es penalizada. Por otra parte, a aquellos términos nuevos para cada lexicón (no aparecen en años anteriores) se les da toda larelevancia correspondiente, al ser considerados términos de relevancia emergente.
Por motivos obvios, el lexicón correspondiente al año 2015 no cuenta con factor de memoria de los años anteriores, ya que este actúa como semilla.

Por otra parte, se ha tenido en consideración el uso de un diccionario médico abierto para darle más peso a los términos estrictamente médicos y así penalizar la relevancia de términos de carácter académico, típicos en el lenguaje de todos los artículos de investigación. En concreto, los mejores resultados se han obtenido dándole un 80 por ciento del peso a aquellos términos del diccionario médico y el resto a los que no están. Essto provoca una separación en la poblaciones claramente visible en los histogramas de las relevancias de los lexicones (ver Figura \ref{fig:hists}). Conforme se aumenta de año, puede verse un ensanchamiento de la población de los términos que se encuentran en el diccionario, fruto de la adición de los términos de años anteriores.

\begin{figure}[htbp]
\centering
\subfigure[2015]{\includegraphics[width=65mm]{img/2015_hist.png}}
\subfigure[2016]{\includegraphics[width=65mm]{img/2016_hist.png}}
\subfigure[2017]{\includegraphics[width=65mm]{img/2017_hist.png}}
\subfigure[2018]{\includegraphics[width=65mm]{img/2018_hist.png}}
\caption{Histograma de relevancias para cada lexicón.} \label{fig:hists}
\end{figure}


\section{Creación de las redes neuronales por año.}
\label{sec:lexis}

Para crear el conjunto de entrenamiento, se cuenta con mas de $100000$ artículos de cada año no utilizados para la creación de los lexicones. Siguiendo el procedimiento descrito en la Sección \ref{sec:red}, se crea un conjunto con $320000$ frases etiquetadas para entrenamiento y $80000$ para test para los 4 lexicones. Se etiquetan como relevantes aquellas frases que contienen 4 o más sustantivos que tengan relevancia $0.7$ o mayor. Se utiliza este valor de corte porque es a partir del cuál se encuentra la mayoría de los términos mas relevantes de la población perteneciente al diccionario médico. Siguiendo este criterio, se realiza un análisis exploratorio con $1000$ del año 2015 no utilizados para la creación del lexicón del que se obtienen los siguientes resultados:
112808 frases totales analizadas, de las cuáles 96682 son etiquetadas como relevantes y   16126 como no relevantes. El alto porcentaje de frases relevantes indica que el lexicón tiene una riqueza aceptable.

Se ha probado con dos conjuntos pre-entrenados de \emph{Word2vect} \cite{goldberg2014word2vec} uno de Google y otro de Glove. En el caso del Modelo de Google, el cuál cuenta con un diccionario de $3000000$ de palabras

\section{Experimentos}
\label{sec:lexis}

\begin{figure}
  \centering
  \includegraphics[width=14cm, keepaspectratio]{img/2016_results_mod.png}
  \caption{Resultados 2016}
  \label{fig:gantt}
\end{figure}  


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONCLUSIONES %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage
\chapter{Conclusiones}
\label{chap:conclusiones}


trabajos futuros:
-mas pruebas variando los parámetros de modulación.
-creación de sistema de embegddings con vocabulario y corpus médico.
-Obtención de correferencias para cada término-
-Utilizacion de una ontologia médica.
-ampliacion del tamaño de los lexicones.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APÉNDICE(S) %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% BIBLIOGRAFIA %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\cleardoublepage

% Las siguientes dos instrucciones es todo lo que necesitas
% para incluir las citas en la memoria
\bibliographystyle{unsrt}
\bibliography{memoria}  % memoria.bib es el nombre del fichero que contiene
% las referencias bibliográficas. Abre ese fichero y mira el formato que tiene,
% que se conoce como BibTeX. Hay muchos sitios que exportan referencias en
% formato BibTeX. Prueba a buscar en http://scholar.google.com por referencias
% y verás que lo puedes hacer de manera sencilla.
% Más información: 
% http://texblog.org/2014/04/22/using-google-scholar-to-download-bibtex-citations/

\end{document}
